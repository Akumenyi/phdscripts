{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script performs a varimax-rotated PCA (R-verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set directory and import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/home/kwesi/terra/research/CMIP5_models/cmip5_smhi/cmip_trbi/roll_freq_matrix/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(datadir + 'zg700_ECMWF-ERAINT_rcp85_r1i1p1_19800101-20131231_matrix.csv',names = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO'], header =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select specific columns in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.iloc[:,0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df); df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extract values at each node of the SOM frequency dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO']\n",
    "\n",
    "## Separating out the nodes\n",
    "x = df.loc[:, nodes].values\n",
    "\n",
    "# Standardizing the nodes\n",
    "x = StandardScaler().fit_transform(x)\n",
    "#%store x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perform factor analysis with varimax rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fan = FactorAnalysis(n_components=n_comps, rotation='varimax').fit(x)\n",
    "#fan.get_covariance().shape\n",
    "\n",
    "fan.components_.T[:,0:3];\n",
    "\n",
    "#get scores of pca\n",
    "fan_scores = fan.transform(x)\n",
    "\n",
    "#calculate explained sample variance\n",
    "n_sample = x.shape[1]\n",
    "exp_v = np.array([(fan.components_.T[:, i]**2).sum()/(n_sample) for i in range(n_comps)]).round(4)\n",
    "print(100*exp_v)\n",
    "\n",
    "#var = np.sum(fan.components_.T**2, axis=0) #coulmn-wise\n",
    "#print(var)\n",
    "#exp_v = (100*(var/np.sum(var))[0:3])\n",
    "#print(exp_v)\n",
    "#display(pd.DataFrame(fan_scores[:,0:3]));\n",
    "#fan.get_covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.bar(range(15),fan.components_[0,:]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(fan_scores[:,0:3],columns = ['RC1', 'RC2','RC3'])\n",
    "df_scores;\n",
    "#df_scores.to_csv(datadir + 'ERAINT_pca_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a dataframe from rotated principal compnents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf = pd.DataFrame(data = fan.components_.T[:,0:3], columns = ['RC1', 'RC2','RC3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf.rename(index={0:'0,0',1:'0,1',2:'0,2',3:'1,0',4:'1,1',5:'1,2',\n",
    "                         6:'2,0',7:'2,1',8:'2,2',9:'3,0',10:'3,1',11:'3,2',\n",
    "                         12:'ITCZInt',13:'NINO34',14:'AAO'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fitting CMIP5 model data to observational data for scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CanESM = pd.read_csv(datadir + 'zg700_CanESM2_rcp85_r1i1p1_19800101-20131231_matrix.csv',names = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO'], header =0)\n",
    "#zg700_CanESM2_rcp85_r1i1p1_19800101-20131231_matrix.csv\n",
    "CanESM_df = CanESM.iloc[:,0:15]\n",
    "CanESM_df.head();\n",
    "\n",
    "\n",
    "#### extract values at each node of the SOM frequency dataset\n",
    "CanESM_nodes = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO']\n",
    "\n",
    "## Separating out the nodes\n",
    "CanESM_x = CanESM_df.loc[:, CanESM_nodes].values\n",
    "\n",
    "# Standardizing the nodes and project to my data\n",
    "CanESM_x = StandardScaler().fit_transform(CanESM_x)\n",
    "#%store CanESM_x\n",
    "\n",
    "#use era interim pca to predict model pca\n",
    "CanESM_scores_x = fan.transform(CanESM_x)\n",
    "\n",
    "#calculate explained sample variance\n",
    "n_sample = x.shape[1]\n",
    "CanESM_var = np.array([(CanESM_scores_x[:, i]**2).sum()/(n_sample-1) for i in range(n_comps)]).round(2)\n",
    "print(CanESM_var[0:3])\n",
    "\n",
    "\n",
    "#var = np.sum(CanESM_scores_x.T**2, axis=1) #coulmn-wise\n",
    "#CanESM_var = 100 * var/np.sum(var)\n",
    "#print(CanESM_var[0:3])\n",
    "\n",
    "CanESM_scores = pd.DataFrame(CanESM_scores_x[:,0:3],columns = ['RC1', 'RC2','RC3'])\n",
    "CanESM_scores;\n",
    "#CanESM_scores.to_csv(datadir + 'CanESM_pca_scores.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNRM = pd.read_csv(datadir + 'zg700_CNRM-CM5_rcp85_r1i1p1_19800101-20131231_matrix.csv',names = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO'], header =0)\n",
    "\n",
    "CNRM_df = CNRM.iloc[:,0:15]\n",
    "#print(CNRM_df.head())\n",
    "\n",
    "\n",
    "#### extract values at each node of the SOM frequency dataset\n",
    "CNRM_nodes = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO']\n",
    "\n",
    "## Separating out the nodes\n",
    "CNRM_x = CNRM_df.loc[:, CNRM_nodes].values\n",
    "\n",
    "# Standardizing the nodes\n",
    "CNRM_x = StandardScaler().fit_transform(CNRM_x)\n",
    "#%store CNRM_x\n",
    "\n",
    "#use era interim pca to predict model pca\n",
    "CNRM_scores_x = fan.transform(CNRM_x)\n",
    "\n",
    "#calculate explained variance\n",
    "#n_sample = x.shape[1]\n",
    "CNRM_var = np.array([(CNRM_scores_x[:, i]**2).sum()/(n_sample-1) for i in range(n_comps)]).round(2)\n",
    "print(CNRM_var[0:3])\n",
    "\n",
    "\n",
    "CNRM_scores_x;\n",
    "\n",
    "CNRM_scores = pd.DataFrame(CNRM_scores_x[:,0:3],columns = ['RC1', 'RC2','RC3'])\n",
    "CNRM_scores;\n",
    "#CNRM_scores.to_csv(datadir +'CNRM_pca_scores.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GFDL = pd.read_csv(datadir + 'zg700_GFDL-ESM2M_rcp85_r1i1p1_19800101-20131231_matrix.csv',names = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO'], header =0)\n",
    "\n",
    "GFDL_df = GFDL.iloc[:,0:15]\n",
    "GFDL_df.head();\n",
    "\n",
    "\n",
    "#### extract values at each node of the SOM frequency dataset\n",
    "GFDL_nodes = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO']\n",
    "\n",
    "## Separating out the nodes\n",
    "GFDL_x = GFDL_df.loc[:, GFDL_nodes].values\n",
    "\n",
    "# Standardizing the nodes\n",
    "GFDL_x = StandardScaler().fit_transform(GFDL_x)\n",
    "#%store GFDL_x\n",
    "\n",
    "#use era interim pca to predict model pca\n",
    "GFDL_scores_x = fan.transform(GFDL_x)\n",
    "\n",
    "#calculate explained variance\n",
    "n_sample = x.shape[1]\n",
    "GFDL_var = np.array([(GFDL_scores_x[:, i]**2).sum()/(n_sample-1) for i in range(n_comps)]).round(2)\n",
    "print(GFDL_var[0:3])\n",
    "\n",
    "GFDL_scores = pd.DataFrame(GFDL_scores_x[:,0:3],columns = ['RC1', 'RC2','RC3'])\n",
    "GFDL_scores;\n",
    "#GFDL_scores.to_csv(datadir + 'GFDL_pca_scores.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HadGEM = pd.read_csv(datadir + 'zg700_HadGEM2-ES_rcp85_r1i1p1_19800101-20131231_matrix.csv',names = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO'], header =0)\n",
    "\n",
    "HadGEM_df = HadGEM.iloc[:,0:15]\n",
    "HadGEM_df.head();\n",
    "\n",
    "\n",
    "#### extract values at each node of the SOM frequency dataset\n",
    "HadGEM_nodes = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO']\n",
    "\n",
    "## Separating out the nodes\n",
    "HadGEM_x = HadGEM_df.loc[:, HadGEM_nodes].values\n",
    "\n",
    "# Standardizing the nodes\n",
    "HadGEM_x = StandardScaler().fit_transform(HadGEM_x)\n",
    "#%store HadGEM_x\n",
    "\n",
    "#use era interim pca to predict model pca\n",
    "HadGEM_scores_x = fan.transform(HadGEM_x)\n",
    "\n",
    "#calculate explained variance\n",
    "n_sample = x.shape[1]\n",
    "HadGEM_var = np.array([(HadGEM_scores_x[:, i]**2).sum()/(n_sample-1) for i in range(n_comps)]).round(2)\n",
    "print(HadGEM_var[0:3])\n",
    "\n",
    "HadGEM_scores = pd.DataFrame(HadGEM_scores_x[:,0:3],columns = ['RC1', 'RC2','RC3'])\n",
    "HadGEM_scores;\n",
    "#HadGEM_scores.to_csv(datadir + 'HadGEM_pca_scores.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPSL = pd.read_csv(datadir + 'zg700_IPSL-CM5A-LR_rcp85_r1i1p1_19800101-20131231_matrix.csv',names = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO'], header =0)\n",
    "\n",
    "IPSL_df = IPSL.iloc[:,0:15]\n",
    "IPSL_df.head();\n",
    "\n",
    "\n",
    "#### extract values at each node of the SOM frequency dataset\n",
    "IPSL_nodes = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO']\n",
    "\n",
    "## Separating out the nodes\n",
    "IPSL_x = IPSL_df.loc[:, IPSL_nodes].values\n",
    "\n",
    "# Standardizing the nodes\n",
    "IPSL_x = StandardScaler().fit_transform(IPSL_x)\n",
    "#%store IPSL_x\n",
    "\n",
    "#use era interim pca to predict model pca\n",
    "IPSL_scores_x = fan.transform(IPSL_x)\n",
    "\n",
    "#calculate explained variance\n",
    "n_sample = x.shape[1]\n",
    "IPSL_var = np.array([(IPSL_scores_x[:, i]**2).sum()/(n_sample-1) for i in range(n_comps)]).round(2)\n",
    "print(IPSL_var)\n",
    "\n",
    "IPSL_scores = pd.DataFrame(IPSL_scores_x[:,0:3],columns = ['RC1', 'RC2','RC3'])\n",
    "IPSL_scores;\n",
    "#IPSL_scores.to_csv(datadir + 'IPSL_pca_scores.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIROC = pd.read_csv(datadir + 'zg700_MIROC-ESM_rcp85_r1i1p1_19800101-20131231_matrix.csv',names = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO'], header =0)\n",
    "\n",
    "MIROC_df = MIROC.iloc[:,0:15]\n",
    "MIROC_df.head();\n",
    "\n",
    "\n",
    "#### extract values at each node of the SOM frequency dataset\n",
    "MIROC_nodes = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO']\n",
    "\n",
    "## Separating out the nodes\n",
    "MIROC_x = MIROC_df.loc[:, MIROC_nodes].values\n",
    "\n",
    "# Standardizing the nodes\n",
    "MIROC_x = StandardScaler().fit_transform(MIROC_x)\n",
    "#%store MIROC_x\n",
    "\n",
    "#use era interim pca to predict model pca\n",
    "MIROC_scores_x = fan.transform(MIROC_x)\n",
    "\n",
    "#calculate explained variance\n",
    "n_sample = x.shape[1]\n",
    "MIROC_var = np.array([(MIROC_scores_x[:, i]**2).sum()/(n_sample-1) for i in range(n_comps)]).round(2)\n",
    "print(MIROC_var)\n",
    "\n",
    "MIROC_scores = pd.DataFrame(MIROC_scores_x[:,0:3],columns = ['RC1', 'RC2','RC3'])\n",
    "MIROC_scores;\n",
    "#MIROC_scores.to_csv(datadir + 'MIROC_pca_scores.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPI = pd.read_csv(datadir + 'zg700_MPI-ESM-LR_rcp85_r1i1p1_19800101-20131231_matrix.csv',names = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO'], header =0)\n",
    "\n",
    "MPI_df = MPI.iloc[:,0:15]\n",
    "MPI_df.head();\n",
    "\n",
    "\n",
    "#### extract values at each node of the SOM frequency dataset\n",
    "MPI_nodes = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO']\n",
    "\n",
    "## Separating out the nodes\n",
    "MPI_x = MPI_df.loc[:, MPI_nodes].values\n",
    "\n",
    "# Standardizing the nodes\n",
    "MPI_x = StandardScaler().fit_transform(MPI_x)\n",
    "#store MPI_x\n",
    "\n",
    "#use era interim pca to predict model pca\n",
    "MPI_scores_x = fan.transform(MPI_x)\n",
    "\n",
    "#calculate explained variance\n",
    "n_sample = x.shape[1]\n",
    "MPI_var = np.array([(MPI_scores_x[:, i]**2).sum()/(n_sample-1) for i in range(n_comps)]).round(2)\n",
    "print(MPI_var[0:3])\n",
    "\n",
    "MPI_scores = pd.DataFrame( MPI_scores_x[:,0:3],columns = ['RC1', 'RC2','RC3'])\n",
    "MPI_scores;\n",
    "#MPI_scores.to_csv(datadir +'MPI_pca_scores.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRI = pd.read_csv(datadir + 'zg700_MRI-CGCM3_rcp85_r1i1p1_19800101-20131231_matrix.csv',names = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO'], header =0)\n",
    "\n",
    "MRI_df = MRI.iloc[:,0:15]\n",
    "MRI_df.head();\n",
    "\n",
    "\n",
    "#### extract values at each node of the SOM frequency dataset\n",
    "MRI_nodes = ['0,0','0,1','0,2','1,0','1,1','1,2','2,0','2,1','2,2','3,0','3,1'\n",
    "         ,'3,2','ITCZInt','NINO34','AAO']\n",
    "\n",
    "## Separating out the nodes\n",
    "MRI_x = MRI_df.loc[:, MRI_nodes].values\n",
    "\n",
    "# Standardizing the nodes\n",
    "MRI_x = StandardScaler().fit_transform(MRI_x)\n",
    "#%store MRI_x\n",
    "\n",
    "#use era interim pca to predict model pca\n",
    "MRI_scores_x = fan.transform(MRI_x)\n",
    "\n",
    "#calculate sample variance\n",
    "n_sample = x.shape[1]\n",
    "MRI_var = np.array([(MRI_scores_x[:, i]**2).sum()/(n_sample-1) for i in range(n_comps)]).round(2)\n",
    "print(MRI_var[0:3])\n",
    "\n",
    "MRI_scores = pd.DataFrame(MRI_scores_x[:,0:3],columns = ['RC1', 'RC2','RC3'])\n",
    "MRI_scores;\n",
    "#MRI_scores.to_csv(datadir + 'MRI_pca_scores.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explained_variance = {'ERAInterim' :[30.0, 19.80, 12.60], 'CanESM':[17.41, 21.65, 20.78],'CNRM':[15.5, 23.88, 21.56], \n",
    "#                      'GFDL':[18.5, 21.17, 19.13], 'HadGEM':[20.21, 18.11, 17.74], 'IPSL':[17.66, 19.09, 23.56], \n",
    "#                      'MIROC':[19.98, 18.82, 21.30], 'MPI':[20.92, 19.69, 16.65], 'MRI':[16.81, 23.25, 19.35]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_var = pd.DataFrame(explained_variance)\n",
    "#print(exp_var.T)\n",
    "#exp_var.T.to_csv(datadir + 'explained_variance_gcms_future_NEW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts=pd.DataFrame()\n",
    "tr = np.var(CNRM_df.iloc[:,12])\n",
    "#ts['var'] = tr.var()\n",
    "print(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts=pd.DataFrame()\n",
    "#tr = df.iloc[:,12].var(axis=0)\n",
    "#ts['var'] = tr.var()\n",
    "#print(tr)\n",
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "#plt.rcParams['font.size'] = 15\n",
    "\n",
    "era = df.iloc[:,12]\n",
    "era.reset_index(drop=True, inplace=True)\n",
    "eraa = (era-np.mean(era))/np.std(era)\n",
    "\n",
    "\n",
    "can = CanESM_df.iloc[:,12]\n",
    "can.reset_index(drop=True, inplace=True)\n",
    "cana = (can-np.mean(can))/np.std(can)\n",
    "\n",
    "#cnr = CNRM_df.iloc[:,12]\n",
    "#cnr.to_csv('test_cnrm.csv')\n",
    "cnr = pd.read_csv('test_cnrm1.csv')\n",
    "cnrb = cnr.iloc[:,1]\n",
    "cnrb.reset_index(drop=True, inplace=True)\n",
    "cnra = (cnrb-np.mean(cnrb))/np.std(cnrb)\n",
    "\n",
    "\n",
    "gfd = GFDL_df.iloc[:,12]\n",
    "gfd.reset_index(drop=True, inplace=True)\n",
    "gfda = (gfd-np.mean(gfd))/np.std(gfd)\n",
    "\n",
    "\n",
    "had = HadGEM_df.iloc[:,12]\n",
    "had.reset_index(drop=True, inplace=True)\n",
    "hada = (had-np.mean(had))/np.std(had)\n",
    "\n",
    "\n",
    "ips = IPSL_df.iloc[:,12]\n",
    "ips.reset_index(drop=True, inplace=True)\n",
    "ipsa = (ips-np.mean(ips))/np.std(ips)\n",
    "\n",
    "\n",
    "mir = MIROC_df.iloc[:,12]\n",
    "mir.reset_index(drop=True, inplace=True)\n",
    "mira = (mir-np.mean(mir))/np.std(mir)\n",
    "\n",
    "\n",
    "mpi = MPI_df.iloc[:,12]\n",
    "mpi.reset_index(drop=True, inplace=True)\n",
    "mpia = (mpi-np.mean(mpi))/np.std(mpi)\n",
    "\n",
    "\n",
    "mri = MRI_df.iloc[:,12]\n",
    "mri.reset_index(drop=True, inplace=True)\n",
    "mria = (mri-np.mean(mri))/np.std(mri)\n",
    "\n",
    "\n",
    "era2 = df.iloc[:,13]\n",
    "era2.reset_index(drop=True, inplace=True)\n",
    "#print(ts)\n",
    "\n",
    "can2 = CanESM_df.iloc[:,13]\n",
    "can2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "cnr2 = CNRM_df.iloc[:,13]\n",
    "cnr2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "gfd2 = GFDL_df.iloc[:,13]\n",
    "gfd2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "had2 = HadGEM_df.iloc[:,13]\n",
    "had2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "ips2 = IPSL_df.iloc[:,13]\n",
    "ips2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "mir2 = MIROC_df.iloc[:,13]\n",
    "mir2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "mpi2 = MPI_df.iloc[:,13]\n",
    "mpi2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "mri2 = MRI_df.iloc[:,13]\n",
    "mri2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "era3 = df.iloc[:,14]\n",
    "era3.reset_index(drop=True, inplace=True)\n",
    "#print(ts)\n",
    "\n",
    "can3 = CanESM_df.iloc[:,14]\n",
    "can3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "cnr3 = CNRM_df.iloc[:,14]\n",
    "cnr3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "gfd3 = GFDL_df.iloc[:,14]\n",
    "gfd3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "had3 = HadGEM_df.iloc[:,14]\n",
    "had3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "ips3 = IPSL_df.iloc[:,14]\n",
    "ips3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "mir3 = MIROC_df.iloc[:,14]\n",
    "mir3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "mpi3 = MPI_df.iloc[:,14]\n",
    "mpi3.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "mri3 = MRI_df.iloc[:,14]\n",
    "mri3.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eraa)\n",
    "plt.plot(era2)\n",
    "plt.plot(era3)\n",
    "plt.title('ERA-Interim')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(cana)\n",
    "plt.plot(can2)\n",
    "plt.plot(can3)\n",
    "plt.title('CanESM')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(cnra)\n",
    "plt.plot(cnr2)\n",
    "plt.plot(cnr3)\n",
    "plt.title('CNRM')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(gfda)\n",
    "plt.plot(gfd2)\n",
    "plt.plot(gfd3)\n",
    "plt.title('GFDL')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(hada)\n",
    "plt.plot(had2)\n",
    "plt.plot(had3)\n",
    "plt.title('HadGEM2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(ipsa)\n",
    "plt.plot(ips2)\n",
    "plt.plot(ips3)\n",
    "plt.title('IPSL')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(mira)\n",
    "plt.plot(mir2)\n",
    "plt.plot(mir3)\n",
    "plt.title('MIROC')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(mpia)\n",
    "plt.plot(mpi2)\n",
    "plt.plot(mpi3)\n",
    "plt.title('MPI')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(mria)\n",
    "plt.plot(mri2)\n",
    "plt.plot(mri3)\n",
    "plt.title('MRI')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era1 = era-np.mean(era)\n",
    "\n",
    "can1 = can-np.mean(can)\n",
    "\n",
    "cnr1 = cnrb-np.mean(cnrb)\n",
    "\n",
    "gfd1 = gfd-np.mean(gfd)\n",
    "\n",
    "had1 = had-np.mean(had)\n",
    "\n",
    "ips1 = ips-np.mean(ips)\n",
    "\n",
    "mir1 = mir-np.mean(mir)\n",
    "\n",
    "mpi1 = (mpi-np.mean(mpi))\n",
    "\n",
    "mri1 = (mri-np.mean(mri))\n",
    "\n",
    "#print(era1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "tr = [[era1], [can1], [cnr1], [gfd1], [had1], [ips1], [mir1], [mpi1], [mri1]]\n",
    "ni = [[era2], [can2], [cnr2], [gfd2], [had2], [ips2], [mir2], [mpi2], [mri2]]\n",
    "aa = [[era3], [can3], [cnr3], [gfd3], [had3], [ips3], [mir3], [mpi3], [mri3]]\n",
    "\n",
    "trbi = []\n",
    "for i in tr:\n",
    "    trb = np.var(i)\n",
    "    trbi.append(trb)    \n",
    "print(trbi)\n",
    "\n",
    "\n",
    "nino = []\n",
    "for j in ni:\n",
    "    nin = np.var(j)\n",
    "    nino.append(nin)    \n",
    "print(nino)\n",
    "\n",
    "\n",
    "aao = []\n",
    "for k in aa:\n",
    "    a = np.var(k)\n",
    "    aao.append(a)    \n",
    "print(aao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample variance for each process index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERAInterimv = [0.65, 0.81, 0.48]\n",
    "CanESMv = [2.94, 0.97, 0.46]\n",
    "CNRMv  =  [2.20, 0.56, 0.46]\n",
    "GFDLv  =  [4.68, 1.37, 0.45]\n",
    "HadGEMv = [4.16, 0.83, 0.53]\n",
    "IPSLv  =  [5.07, 1.21, 0.38]\n",
    "MIROCv =  [1.90, 0.78, 0.55]\n",
    "MPIv   =  [1.17, 1.29, 0.48]\n",
    "MRIv   =  [1.29, 1.01, 0.41]\n",
    "\n",
    "x = np.arange(len(CanESMv))  # the label locations\n",
    "width = 0.1  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "#ax = fig.add_subplot(111)\n",
    "rects0 = ax.bar(x - width/2, ERAInterimv, width,edgecolor='black',label='ERA-Interim')\n",
    "rects1 = ax.bar(x + width/2, CanESMv, width,edgecolor='black',label='CanESM2')\n",
    "rects2 = ax.bar(x + 3*width/2, CNRMv, width, edgecolor='black',label='CNRM-CM5')\n",
    "rects3 = ax.bar(x + 5*width/2, GFDLv, width, edgecolor='black', label='GFDL-ESM2M')\n",
    "rects4 = ax.bar(x + 7*width/2, HadGEMv, width, edgecolor='black', label='HadGEM2-ES')\n",
    "rects5 = ax.bar(x + 9*width/2, IPSLv, width, edgecolor='black', label='IPSL-CM5A-LR')\n",
    "rects6 = ax.bar(x + 11*width/2, MIROCv, width, edgecolor='black', label='MIROC-ESM')\n",
    "rects7 = ax.bar(x + 13*width/2, MPIv, width, edgecolor='black', label='MPI-ESM-LR')\n",
    "rects8 = ax.bar(x + 15*width/2, MRIv, width, edgecolor='black', label='MRI-CGCM3')\n",
    "\n",
    "# Fix the x-axes.\n",
    "lab = ['TRBI', 'NINO34', 'AAO', 'residuals'] #['ERA-Interim','CanESM2','CNRM-CM5','GFDL-ESM2M', 'HadGEM2-ES', 'MIROC-ESM','MPI-ESM-LR','MRI-CGCM3']   \n",
    "ax.set_xticks(x + 7*width / 2)\n",
    "ax.set_xticklabels(lab,fontsize=10)\n",
    "plt.ylabel('Sample Variance',fontsize=18)\n",
    "ax.legend(fontsize=13)\n",
    "\n",
    "\n",
    "# create a function\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',fontsize=10)\n",
    "autolabel(rects0)\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "autolabel(rects5)\n",
    "autolabel(rects6)\n",
    "autolabel(rects7)\n",
    "autolabel(rects8)\n",
    "\n",
    "fig.tight_layout()\n",
    "#plt.savefig(datadir2 + 'sample_variance_gcms_hist_v1.png',bbox_inches='tight', dpi = 600) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot explained variances for RCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir2 = '/terra/users/csag/kwesi/research/future/pca_matrices/' \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERAInterimh = [30.0, 19.8, 12.6, 37.6]\n",
    "CanESMh = [19.9, 16.6, 22.7, 40.8]\n",
    "CNRMh  =  [13.9, 23.3, 28.3, 34.5]\n",
    "GFDLh  =  [17.3, 20.8, 22.6, 39.0]\n",
    "HadGEMh = [20.1, 18.2, 22.9, 38.8]\n",
    "IPSLh  =  [20.2, 18.5, 27.0, 37.3]\n",
    "MIROCh =  [17.8, 24.3, 16.7, 41.2]\n",
    "MPIh   =  [20.5, 17.9, 23.3, 38.3]\n",
    "MRIh   =  [17.4, 22.8, 22.9, 36.9]\n",
    "\n",
    "x = np.arange(len(CanESMh))  # the label locations\n",
    "width = 0.1  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "#ax = fig.add_subplot(111)\n",
    "rects0 = ax.bar(x - width/2, ERAInterimh, width,edgecolor='black',label='ERA-Interim')\n",
    "rects1 = ax.bar(x + width/2, CanESMh, width,edgecolor='black',label='CanESM2')\n",
    "rects2 = ax.bar(x + 3*width/2, CNRMh, width, edgecolor='black',label='CNRM-CM5')\n",
    "rects3 = ax.bar(x + 5*width/2, GFDLh, width, edgecolor='black', label='GFDL-ESM2M')\n",
    "rects4 = ax.bar(x + 7*width/2, HadGEMh, width, edgecolor='black', label='HadGEM2-ES')\n",
    "rects5 = ax.bar(x + 9*width/2, IPSLh, width, edgecolor='black', label='IPSL-CM5A-LR')\n",
    "rects6 = ax.bar(x + 11*width/2, MIROCh, width, edgecolor='black', label='MIROC-ESM')\n",
    "rects7 = ax.bar(x + 13*width/2, MPIh, width, edgecolor='black', label='MPI-ESM-LR')\n",
    "rects8 = ax.bar(x + 15*width/2, MRIh, width, edgecolor='black', label='MRI-CGCM3')\n",
    "\n",
    "# Fix the x-axes.\n",
    "lab = ['PC1', 'PC2', 'PC3', 'residuals']\n",
    "ax.set_xticks(x + 7*width / 2)\n",
    "ax.set_xticklabels(lab,fontsize=18)\n",
    "plt.ylabel('Explained Variance (%)',fontsize=18)\n",
    "ax.legend(fontsize=10.5)\n",
    "\n",
    "\n",
    "# create a function\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',fontsize=8.5)\n",
    "autolabel(rects0)\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "autolabel(rects5)\n",
    "autolabel(rects6)\n",
    "autolabel(rects7)\n",
    "autolabel(rects8)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(datadir2 + 'explained_variance_gcms_hist_withresiduals_v1.png',bbox_inches='tight', dpi = 600) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ERAInterim = [37.6]\n",
    "CanESM = [40.1]\n",
    "CNRM  =  [39.0]\n",
    "GFDL  =  [41.2]\n",
    "HadGEM = [44.0]\n",
    "IPSL  =  [39.5]\n",
    "MIROC =  [40.0]\n",
    "MPI   =  [42.7]\n",
    "MRI   =  [40.5]\n",
    "\n",
    "\n",
    "x = np.arange(len(CanESM))  # the label locations\n",
    "width = 0.1  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "rects0 = ax.bar(x - width/2, ERAInterim, width,edgecolor='black',label='ERA-Interim')\n",
    "rects1 = ax.bar(x + width/2, CanESM, width,edgecolor='black',label='CanESM')\n",
    "rects2 = ax.bar(x + 3*width/2, CNRM, width, edgecolor='black',label='CNRM')\n",
    "rects3 = ax.bar(x + 5*width/2, GFDL, width, edgecolor='black', label='GFDL')\n",
    "rects4 = ax.bar(x + 7*width/2, HadGEM, width, edgecolor='black', label='HadGEM')\n",
    "rects5 = ax.bar(x + 9*width/2, IPSL, width, edgecolor='black', label='IPSL')\n",
    "rects6 = ax.bar(x + 11*width/2, MIROC, width, edgecolor='black', label='MIROC')\n",
    "rects7 = ax.bar(x + 13*width/2, MPI, width, edgecolor='black', label='MPI')\n",
    "rects8 = ax.bar(x + 15*width/2, MRI, width, edgecolor='black', label='MRI')\n",
    "\n",
    "# Fix the x-axes.\n",
    "lab = ['residuals']\n",
    "ax.set_xticks(x + 7*width / 2)\n",
    "ax.set_xticklabels(lab,fontsize=18)\n",
    "plt.ylabel('Explained Variance (%)',fontsize=18)\n",
    "#ax.legend()\n",
    "\n",
    "\n",
    "# create a function\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects0)\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "autolabel(rects5)\n",
    "autolabel(rects6)\n",
    "autolabel(rects7)\n",
    "autolabel(rects8)\n",
    "fig.tight_layout()\n",
    "#plt.savefig(datadir + 'residuals_explained_variance_gcms_future[1].png',bbox_inches='tight', dpi = 600) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayify_cmap(cmap):\n",
    "    \"\"\"Return a grayscale version of the colormap\"\"\"\n",
    "    cmap = plt.cm.get_cmap(cmap)\n",
    "    colors = cmap(np.arange(cmap.N))\n",
    "    \n",
    "    # convert RGBA to perceived greyscale luminance\n",
    "    # cf. http://alienryderflex.com/hsp.html\n",
    "    RGB_weight = [0.299, 0.587, 0.114]\n",
    "    luminance = np.sqrt(np.dot(colors[:, :3] ** 2, RGB_weight))\n",
    "    colors[:, :3] = luminance[:, np.newaxis]\n",
    "    \n",
    "    return cmap.from_list(cmap.name + \"_grayscale\", colors, cmap.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### heatmap for era-interim SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmp = pd.read_csv('/terra/users/csag/kwesi/research/test_freq_trendy.csv',names = ['seas','freq','trend','node'], header =0)\n",
    "print(htmp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select season of interest\n",
    "djf = htmp.query(\"seas in ['DJF']\")\n",
    "djf.head()\n",
    "\n",
    "\n",
    "#select values and reshape to fit the 4 by 3 matrix for heatmap\n",
    "djf_arr = np.array(djf.iloc[:,1]).reshape(3,4)\n",
    "DF_djf = pd.DataFrame(djf_arr[:,:])\n",
    "#print(DF_djf)\n",
    "\n",
    "\n",
    "#make a dictionary to force plot in a strict order...'sorted' failed to do that huh!\n",
    "headers_x = {1:'9',2:'10',3:'11',4:'12'}\n",
    "\n",
    "xlist =[]\n",
    "for key, value in headers_x.items():\n",
    "    xlist.append(value)\n",
    "    \n",
    "headers_y = {1: '1', 2: '5', 3: '9'}\n",
    "\n",
    "ylist =[]\n",
    "for key, value in headers_y.items():\n",
    "    ylist.append(value)\n",
    "\n",
    "    \n",
    "#plot the heatmap    \n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "fig.subplots_adjust(bottom=0.25,left=0.25) # make room for labels\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "mmin = 1\n",
    "mmax = 20\n",
    "\n",
    "bounds = np.linspace(1, 20,40)\n",
    "norm = colors.BoundaryNorm(boundaries=bounds, ncolors=256)\n",
    "\n",
    "\n",
    "heatmap = ax.pcolor(DF_djf,edgecolors='k',norm=norm,cmap = 'Greys',vmin=mmin,vmax=mmax, linewidth=0.5) #norm=norm,grayify_cmap('bwr')\n",
    "#sns.heatmap(DF_djf,cmap=\"YlGnBu\")\n",
    "#cbar = plt.colorbar(heatmap,ticks=np.arange(1,22,2))  \n",
    "\n",
    "# Loop over data dimensions and create text annotations\n",
    "data = np.array(DF_djf)\n",
    "data_rav = data.ravel()\n",
    "for y in range(data.shape[0]):\n",
    "    for x in range(data.shape[1]):\n",
    "        if data_rav[0] < 0.05:\n",
    "            plt.plot(DF_djf + 0.5, DF_djf + 0.5, marker='o', markersize=2, color=\"k\")\n",
    "        plt.text(x + 0.5, y + 0.5, '%.0f' % data[y, x],\n",
    "                 horizontalalignment='center',\n",
    "                 verticalalignment='center', color=\"r\",fontsize=15)\n",
    "\n",
    "# Set ticks in center of cells\n",
    "ax.set_xticks(np.arange(DF_djf.shape[1]) + 0.5, minor=False)\n",
    "ax.set_yticks(np.arange(DF_djf.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "# want a more natural, table-like display\n",
    "ax.invert_yaxis()\n",
    "#ax.xaxis.tick_top()\n",
    "\n",
    "\n",
    "# Rotate the xlabels. Set both x and y labels to headers[0:]\n",
    "ax.set_xticklabels(xlist[0:],fontsize=12) #,rotation=90\n",
    "ax.set_yticklabels(ylist[0:],fontsize=12)\n",
    "#ax.set_xlabel('SOM nodes',fontsize=15)\n",
    "#ax.set_ylabel('SOM nodes',fontsize=15) \n",
    "\n",
    "#saving plot\n",
    "plt.savefig('/home/kwesi/terra/research/paper2/plots/SOM_reanalysis_heatmap_djf_P3a.png',bbox_inches='tight', dpi = 600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select season of interest\n",
    "jja = htmp.query(\"seas in ['JJA']\")\n",
    "jja.head()\n",
    "\n",
    "\n",
    "#select values and reshape to fit the 4 by 3 matrix for heatmap\n",
    "jja_arr = np.array(jja.iloc[:,1]).reshape(3,4)\n",
    "DF_jja = pd.DataFrame(jja_arr[:,:])\n",
    "#print(DF_jja)\n",
    "\n",
    "\n",
    "#make a dictionary to force plot in a strict order...'sorted' failed to do that huh!\n",
    "headers_x = {1:'9',2:'10',3:'11',4:'12'}\n",
    "\n",
    "xlist =[]\n",
    "for key, value in headers_x.items():\n",
    "    xlist.append(value)\n",
    "    \n",
    "headers_y = {1: '1', 2: '5', 3: '9'}\n",
    "\n",
    "ylist =[]\n",
    "for key, value in headers_y.items():\n",
    "    ylist.append(value)\n",
    "\n",
    "    \n",
    "#plot the heatmap    \n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "fig.subplots_adjust(bottom=0.25,left=0.25) # make room for labels\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "mmin = 1\n",
    "mmax = 20\n",
    "\n",
    "bounds = np.linspace(1, 20,40)\n",
    "norm = colors.BoundaryNorm(boundaries=bounds, ncolors=256)\n",
    "\n",
    "\n",
    "heatmap = ax.pcolor(DF_jja,edgecolors='k',norm=norm,cmap = 'Greys',vmin=mmin,vmax=mmax, linewidth=0.5) #norm=norm,grayify_cmap('bwr')\n",
    "#sns.heatmap(DF_djf,cmap=\"YlGnBu\")\n",
    "#cbar = plt.colorbar(heatmap,ticks=np.arange(1,22,2))  \n",
    "\n",
    "# Loop over data dimensions and create text annotations\n",
    "data = np.array(DF_jja)\n",
    "data_rav = data.ravel()\n",
    "for y in range(data.shape[0]):\n",
    "    for x in range(data.shape[1]):\n",
    "        if data_rav[0] < 0.05:\n",
    "            plt.plot(DF_jja + 0.5, DF_jja + 0.5, marker='o', markersize=2, color=\"k\")\n",
    "        plt.text(x + 0.5, y + 0.5, '%.0f' % data[y, x],\n",
    "                 horizontalalignment='center',\n",
    "                 verticalalignment='center', color=\"red\",fontsize=15)\n",
    "\n",
    "# Set ticks in center of cells\n",
    "ax.set_xticks(np.arange(DF_jja.shape[1]) + 0.5, minor=False)\n",
    "ax.set_yticks(np.arange(DF_jja.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "# want a more natural, table-like display\n",
    "ax.invert_yaxis()\n",
    "#ax.xaxis.tick_top()\n",
    "\n",
    "# Rotate the xlabels. Set both x and y labels to headers[0:]\n",
    "ax.set_xticklabels(xlist[0:],fontsize=12) #,rotation=90\n",
    "ax.set_yticklabels(ylist[0:],fontsize=12)\n",
    "#ax.set_xlabel('SOM nodes',fontsize=15)\n",
    "#ax.set_ylabel('SOM nodes',fontsize=15) \n",
    "\n",
    "#saving plot\n",
    "plt.savefig('/home/kwesi/terra/research/paper2/plots/SOM_reanalysis_heatmap_jja_P3a.png',bbox_inches='tight', dpi = 600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other ways of calculating explained variance===>there are some variations in there but most agree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_var_pca = np.var(IPSL_scores_x, axis=0) / np.sum(np.var(IPSL_scores_x, axis=0))\n",
    "print('explained variance pca: ', 100*expl_var_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# some sample data\n",
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000)).cumsum()\n",
    "\n",
    "#plot the time series\n",
    "ts.plot(style='k--')\n",
    "\n",
    "# calculate a 60 day rolling mean and plot\n",
    "ts.rolling(window=60).mean().plot(style='k')\n",
    "\n",
    "# add the 20 day rolling standard deviation:\n",
    "ts.rolling(window=20).std().plot(style='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### alternatively;\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 9\n",
    "plt.rcParams['figure.dpi'] = 130\n",
    "\n",
    "\n",
    "ERAInterim = [30.0, 19.80, 12.60]\n",
    "CanESM = [17.41,  21.65,  20.78]\n",
    "CNRM  =  [15.50,  23.88,  21.56]\n",
    "GFDL  =  [18.50,  21.17,  19.13]\n",
    "HadGEM = [20.21,  18.11,  17.74]\n",
    "IPSL  =  [17.66,  19.09,  23.56]\n",
    "MIROC =  [19.98,  18.82,  21.30]\n",
    "MPI   =  [20.92,  19.69,  16.65]\n",
    "MRI   =  [16.81,  23.25,  19.35]\n",
    "\n",
    "\n",
    "\n",
    "#create a custom colormap python\n",
    "tableau_20 =[(31,119,180),(174,199,232),(255,127,14),(255,187,120),\n",
    "            (44,160,44),(152,223,138),(214,39,40),(255,152,150),\n",
    "            (148,103,189),(197,176,213),(140,86,75),(196,156,148),\n",
    "            (227,119,194),(247,182,210),(127,127,127),(199,199,199),\n",
    "            (188,189,34),(219,219,141),(23,190,207),(158,218,229)]\n",
    "\n",
    "#           [steelblue,lightsteelblue,darkorange,peach(sandybrown),\n",
    "#           green,lightgreen,crimsonred,lightcoral,\n",
    "#           mediumpurple,palepurple,brown,darksalmon,\n",
    "#           violet,pink,dimgrey,darkgrey,\n",
    "#           olive,palegoldenrod,lightseagreen,powderblue]\n",
    "\n",
    "#scaling above RBG values to [0,1] range, which is Matplotlib acceptable format:\n",
    "for i in range(len(tableau_20)):\n",
    "    r, g, b = tableau_20[i]\n",
    "    tableau_20[i] = (r/255., g/255., b/255.)\n",
    "    #plt.plot(tableau_20[i])\n",
    "    #plt.pcolor(tableau_20)\n",
    "\n",
    "labels = ['CanESM', 'CNRM', 'GFDL', 'HadGEM', 'IPSL', 'MIROC', 'MPI', 'MRI']\n",
    "\n",
    "\n",
    "\n",
    "# set width of bar\n",
    "barWidth = 0.1\n",
    "\n",
    "# Set position of bar on X axis\n",
    "r0 = np.arange(len(ERAInterim))\n",
    "r1 = [x + barWidth for x in r0]\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "r4 = [x + barWidth for x in r3]\n",
    "r5 = [x + barWidth for x in r4] \n",
    "r6 = [x + barWidth for x in r5]\n",
    "r7 = [x + barWidth for x in r6]\n",
    "r8 = [x + barWidth for x in r7]\n",
    " \n",
    "# Make the plot\n",
    "#3,5/6,7,8,9/10,12,15,17\n",
    "plt.bar(r0, ERAInterim, color=tableau_20[1], width=barWidth, edgecolor='black', label='ERA-Interim')\n",
    "plt.bar(r1, CanESM, color=tableau_20[3], width=barWidth, edgecolor='black', label='CanESM')\n",
    "plt.bar(r2, CNRM, color=tableau_20[5], width=barWidth, edgecolor='black', label='CNRM')\n",
    "plt.bar(r3, GFDL, color=tableau_20[6], width=barWidth, edgecolor='black', label='GFDL')\n",
    "plt.bar(r4, HadGEM, color=tableau_20[8], width=barWidth, edgecolor='black', label='HadGEM2')\n",
    "plt.bar(r5, IPSL, color=tableau_20[2], width=barWidth, edgecolor='black', label='IPSL')\n",
    "plt.bar(r6, MIROC, color=tableau_20[10], width=barWidth, edgecolor='black', label='MIROC')\n",
    "plt.bar(r7, MPI, color=tableau_20[7], width=barWidth, edgecolor='black', label='MPI')\n",
    "plt.bar(r8, MRI, color=tableau_20[15], width=barWidth, edgecolor='black', label='MRI')\n",
    "\n",
    "\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('Components', fontweight='bold')\n",
    "plt.xticks([r + 4.5*barWidth for r in range(len(CanESM))], ['RC1', 'RC2', 'RC3'])\n",
    " \n",
    "# Create legend & Show graphic\n",
    "plt.legend(loc='upper right')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
